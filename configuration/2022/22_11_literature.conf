// --- UPDATE THIS --- //
spark-settings.write-mode = "ignore"
data_version = "22.11"
chembl_version = "31"
ensembl_version = "108"
efo_version = "v3.47.0"
evidences.data-sources-exclude = ["ot_crispr", "encore", "ot_crispr_validation"]
# update defaults for next release
etl-dag.resolve = false
// --- END - UPDATE THIS --- //
target.input.chemical-probes.path = "gs://open-targets-pre-data-releases/22.11/input/target-inputs/chemicalprobes/chemicalprobes.json.gz"
literature.processing.abstracts.path = "gs://otar025-epmc/Abstracts/**/*.jsonl"
literature.processing.full-texts.path = "gs://otar025-epmc/Full-text/**/*.jsonl"
//literature.processing.full-texts.path = "gs://otar025-epmc/Full-text/**/*.jsonl"
common.additional-outputs = []
common.output-format = "parquet"

//literature.processing.diseases.format = "json"
//literature.processing.targets.format = "json"
//literature.processing.drugs.format = "json"

spark-settings.default-spark-session-config +=  {k: "spark.sql.shuffle.partitions", v: "960"}
spark-settings.default-spark-session-config +=  {k: "spark.default.parallelism", v: "960"}
spark-settings.default-spark-session-config +=  {k: "spark.executor.cores", v: "8"}
spark-settings.default-spark-session-config +=  {k: "spark.dynamicAllocation.maxExecutors", v: "60"}
spark-settings.default-spark-session-config +=  {k: "spark.dynamicAllocation.minExecutors", v: "1"}
spark-settings.default-spark-session-config +=  {k: "spark.sql.files.maxRecordsPerFile", v: "100000"}
